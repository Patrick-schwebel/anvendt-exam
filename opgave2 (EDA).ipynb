{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se chunk 2, den f√∏rste crsahede ret sent for mig "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing category: Clothing, Shoes and Jewelry\n",
      "Basic Statistics: {'Total Reviews': 32292099, 'Average Rating': 4.189458449263394, 'Average Review Length': 158.12622289071717, 'Average Summary Length': 21.565853695260873}\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from collections import Counter\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from textblob import TextBlob\n",
    "import numpy as np\n",
    "\n",
    "# Function to load the dataset\n",
    "def load_dataset(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = [json.loads(line) for line in file]\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Function to calculate basic statistics\n",
    "def calculate_basic_stats(df):\n",
    "    return {\n",
    "        \"Total Reviews\": len(df),\n",
    "        \"Average Rating\": df['overall'].mean(),\n",
    "        \"Average Review Length\": df['reviewText'].str.len().mean(),\n",
    "        \"Average Summary Length\": df['summary'].str.len().mean()\n",
    "    }\n",
    "\n",
    "# Function to find the most common words\n",
    "def get_most_common_words(text_series, num_words=10):\n",
    "    combined_text = ' '.join(text_series.dropna())\n",
    "    words = re.findall(r'\\b[a-z]+\\b', combined_text.lower())\n",
    "    return Counter(words).most_common(num_words)\n",
    "\n",
    "def analyze_category(data, category_name):\n",
    "    \"\"\"Function to perform EDA on a given category.\"\"\"\n",
    "    print(f\"Analyzing category: {category_name}\")\n",
    "\n",
    "    # Basic Statistics\n",
    "    basic_stats = calculate_basic_stats(data)\n",
    "    print(\"Basic Statistics:\", basic_stats)\n",
    "\n",
    "    # Common Words in Reviews and Summaries\n",
    "    common_words_reviews = get_most_common_words(data['reviewText'])\n",
    "    common_words_summaries = get_most_common_words(data['summary'])\n",
    "    print(\"Common Words in Reviews:\", common_words_reviews)\n",
    "    print(\"Common Words in Summaries:\", common_words_summaries)\n",
    "\n",
    "    # Distribution of Ratings\n",
    "    rating_counts = data['overall'].value_counts()\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=rating_counts.index, y=rating_counts.values)\n",
    "    plt.title(f\"Distribution of Ratings in {category_name}\")\n",
    "    plt.xlabel('Ratings')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "    # Review Length Analysis\n",
    "    data['review_length'] = data['reviewText'].str.len()\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(data['review_length'], bins=50, kde=True)\n",
    "    plt.title(f\"Distribution of Review Lengths in {category_name}\")\n",
    "    plt.xlabel('Review Length (Characters)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "    # Analysis for each rating\n",
    "    for rating in sorted(data['overall'].unique()):\n",
    "        analyze_ratings(data[data['overall'] == rating], rating)\n",
    "\n",
    "def analyze_ratings(data, rating):\n",
    "    \"\"\"Function to perform analysis specific to each rating.\"\"\"\n",
    "    print(f\"Analyzing Rating: {rating}\")\n",
    "\n",
    "    # Word Cloud for each rating\n",
    "    words = ' '.join([text for text in data['reviewText'].dropna()])\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(words)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.title(f\"Word Cloud for Rating {rating}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    # Sentiment Analysis\n",
    "    data['sentiment'] = data['reviewText'].apply(lambda x: TextBlob(str(x)).sentiment.polarity)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(data['sentiment'], bins=50, kde=True)\n",
    "    plt.title(f\"Sentiment Distribution for Rating {rating}\")\n",
    "    plt.xlabel('Sentiment Polarity')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "# Load the datasets (replace with the correct file paths)\n",
    "df_clothing = load_dataset('/Users/patrickbendorffschwebel/Desktop/Anvendt-kode/Clothing_Shoes_and_Jewelry.json')\n",
    "df_beauty = load_dataset('/Users/patrickbendorffschwebel/Desktop/Anvendt-kode/All_Beauty.json')\n",
    "\n",
    "#Perform EDA on each category\n",
    "analyze_category(df_clothing, \"Clothing, Shoes and Jewelry\")\n",
    "analyze_category(df_beauty, \"All Beauty\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "den her er opdateret EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from textblob import TextBlob\n",
    "import json\n",
    "\n",
    "def load_sample_dataset(file_path, sample_size):\n",
    "    \"\"\" Load a sample of the dataset \"\"\"\n",
    "    try:\n",
    "        df = pd.read_json(file_path, lines=True)\n",
    "        return df.sample(n=min(sample_size, len(df)))\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def plot_rating_distribution(df, category_name):\n",
    "    \"\"\" Plot the distribution of ratings \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(x='overall', data=df)\n",
    "    plt.title(f\"Rating Distribution in {category_name}\")\n",
    "    plt.xlabel('Rating')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "def plot_review_length_distribution(df, category_name, column_name):\n",
    "    \"\"\" Plot the distribution of review lengths \"\"\"\n",
    "    df['review_length'] = df[column_name].apply(lambda x: len(str(x).split()))\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(df['review_length'], bins=50)\n",
    "    plt.title(f\"Review Length Distribution in {category_name}\")\n",
    "    plt.xlabel('Length of Review (Words)')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "def display_word_cloud(df, column, title):\n",
    "    \"\"\" Display a word cloud for a specific column \"\"\"\n",
    "    text = ' '.join(df[column].dropna().astype(str))\n",
    "    wordcloud = WordCloud(width=800, height=400).generate(text)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Define the file paths and sample sizes for each category\n",
    "categories = {\n",
    "    'AMAZON_FASHION': '/Users/patrickbendorffschwebel/Desktop/Anvendt-kode/anvendt-exam/mappe uden navn 2/AMAZON_FASHION.json',\n",
    "    'Clothing_Shoes_and_Jewelry': '/Users/patrickbendorffschwebel/Desktop/Anvendt-kode/anvendt-exam/mappe uden navn 2/Clothing_Shoes_and_Jewelry.json',\n",
    "    'All_Beauty': '/Users/patrickbendorffschwebel/Desktop/Anvendt-kode/anvendt-exam/mappe uden navn 2/All_Beauty.json',\n",
    "    'Appliances': '/Users/patrickbendorffschwebel/Desktop/Anvendt-kode/anvendt-exam/mappe uden navn 2/Appliances.json',\n",
    "    'Toys_and_Games': '/Users/patrickbendorffschwebel/Desktop/Anvendt-kode/anvendt-exam/mappe uden navn 2/Toys_and_Games.json',\n",
    "    'Arts_Crafts_and_Sewing': '/Users/patrickbendorffschwebel/Desktop/Anvendt-kode/anvendt-exam/mappe uden navn 2/Arts_Crafts_and_Sewing.json',\n",
    "    'Grocery_and_Gourmet_Food': '/Users/patrickbendorffschwebel/Desktop/Anvendt-kode/anvendt-exam/mappe uden navn 2/Grocery_and_Gourmet_Food.json',\n",
    "    'Tools_and_Home_Improvement': '/Users/patrickbendorffschwebel/Desktop/Anvendt-kode/anvendt-exam/mappe uden navn 2/Tools_and_Home_Improvement.json'\n",
    "}\n",
    "sample_size = 5000  # Adjust as needed\n",
    "\n",
    "for category, path in categories.items():\n",
    "    df = load_sample_dataset(path, sample_size)\n",
    "    if not df.empty:\n",
    "        plot_rating_distribution(df, category)\n",
    "        plot_review_length_distribution(df, category, 'reviewText')\n",
    "        plot_review_length_distribution(df, category, 'summary')\n",
    "        display_word_cloud(df, 'reviewText', f\"Common Words in {category} Reviews\")\n",
    "        display_word_cloud(df, 'summary', f\"Common Words in {category} Summaries\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
